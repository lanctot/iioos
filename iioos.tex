%File: formatting-instruction.tex
\documentclass[letterpaper]{article}
\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{color}
\usepackage{textcomp}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{comment}

\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}
\pdfinfo{
/Title (Searching Imperfect Information Games using Online Counterfactual Regret Minimization)
/Author (Authors)}
\setcounter{secnumdepth}{0}  
 \begin{document}
% The file aaai.sty is the style file for AAAI Press 
% proceedings, working notes, and technical reports.
%
\title{Monte Carlo Tree Search in Imperfect Information Games\\using Online Counterfactual Regret Minimization}
\author{Authors}
%\author{Author info\\
%Association for the Advancement of Artificial Intelligence\\
%2275 East Bayshore Road, Suite 160\\
%Palo Alto, California 94303\\

% the note center!
\definecolor{darkgreen}{RGB}{0,125,0}
\newcounter{vlNoteCounter}
\newcounter{mlNoteCounter}
\newcounter{asNoteCounter}
\newcommand{\vlnote}[1]{{\scriptsize \color{blue} $\blacksquare$ \refstepcounter{vlNoteCounter}\textsf{[VL]$_{\arabic{vlNoteCounter}}$:{#1}}}}
\newcommand{\mlnote}[1]{{\scriptsize \color{darkgreen} $\blacksquare$ \refstepcounter{mlNoteCounter}\textsf{[ML]$_{\arabic{mlNoteCounter}}$:{#1}}}}
\newcommand{\asnote}[1]{{\scriptsize \color{red} $\blacktriangle$ \refstepcounter{asNoteCounter}\textsf{[AS]$_{\arabic{asNoteCounter}}$:{#1}}}}

%\newcounter{NoteCounter}
%\newcommand{\vlnote}[1]{{\scriptsize \color{blue} \refstepcounter{vlNoteCounter}\textsf{[VL]$_{\arabic{vlNoteCounter}}$:{#1}}}}
%\renewcommand{\vlnote}[1]{}

\maketitle

\begin{abstract}
Online search in games has been a classic interest of artificial intelligence.
Advances made in search for perfect information games (such as Chess, Checkers, Go, and Backgammon) have led to AI capable of defeating the world's top human experts. 
The progress of search in imperfect information games (such as Poker, Bridge, and Skat) has comparatively lagged behind, due mainly to the complexities introduced by hidden information. 
In this paper, we present Online Outcome Sampling (OOS), the first imperfect information search algorithm with formal guarantees of convergence to an equilibrium strategy.   
In addition, we show that OOS avoids the common problems encountered by determinization.
We evaluate the practical performance and convergence rate of OOS and compare to two modern imperfect information search algorithms.
OOS is shown to outperform its competitors in randomly generated game trees as well as several complex domains: 
Dudo, Phantom Tic-Tac-Toe, and (a bigger one). 
\end{abstract}

\section{Introduction}

%Main points: 
%\begin{itemize}
%\item motivate importance of convergence to NE. 
%\item why online search vs. offline equilibrium computation
%\item existing methods may not converge over time (it would be great to have a motivating example that convinces the reader that any determinization-based II search algorithm cannot converge in general - some kind of search game could be a good example)
%\item introduce the first one that does, and show that it can compete with the others in practice
%\end{itemize}

Search in game-playing has been a classic interest of artificial intelligence. The field of has benefited 
from decades of research focused on perfect information games, as evidenced by events such the as defeat of human chess champions, 
solving of checkers, and the growing strength of computer Go programs~\cite{Campbell02deepblue,Schaeffer07gameover,Gelly12}.
Due to the the complexity and problems introduced by hidden information, search in imperfect information games has received 
comparatively much less attention. This is unfortunate as many games that interest humans have some element of hidden information. 

Modern approaches to imperfect information search use different forms of {\it determinization} to sample game states, then run 
searches rooted from these states, aggregating the values and estimated and maintained by each search to form a final recommendation. 
The most extreme form, Perfect Information Monte Carlo (PIMC)~\cite{Long10Understanding}, ``averages over clairvoyance''~\cite{AIBook}
ignoring the game's information structure completely. The PIMC approach but did not work well in both simplified (Kuhn) poker and 
Monte Carlo Tree Search (MCTS) applied to Kriegspiel~\cite{Ciancarini10Kriegspiel}. 
As was successful in Kriegspiel, most recent algorithms try fix the problems by accounting for the information structure during the 
search in some way. These approaches seem to improve performance in Kriegspiel, Skat~\cite{Furtak13Recursive}, 
Scotland Yard~\cite{Nijssen12SY}, Dou Di Zhu, Magic: The Gathering, and other card games~\cite{Cowling12MTG,Cowling12ISMCTS}.

%For example, the notion of a subgame is required for backward induction, 
%which most perfect information search algorithms are based on, is not well-defined in imperfect information games. 

The main problem with the current techniques is that none have been shown to be {\it consistent}. 
That is, it is not known whether any of the current algorithms provably compute a Nash equilibrium strategy, even if given 
infinite time. In fact, there is practical evidence suggesting that some of these techniques will not converge to an 
equilibrium at all, even in very small games like Biased Rock-Paper-Scissors and Kuhn poker~\cite{Shafiei09,Ponsen11Computing}.
In perfect information search, consistency is often easier to ensure since the algorithms are based on backward induction. 

In this paper, we start by formalizing the problem of imperfect information search from the ground up. That is, we return to the game-theoretic 
foundations upon which search is built to motivate the importance of consistency and to better explain the subtleties introduced by imperfect 
information. 
We introduce Online Outcome Sampling (OOS), a simulation-based MCTS-like algorithm that builds its search tree incrementally. 
We formally prove that OOS converges to an equilibrium strategy as time increases, making it the first 
known consistent imperfect information search algorithm.
We show the empirical convergence rates and performance of OOS, comparing them to two modern imperfect information search algorithms: 
IS-MCTS~\cite{Cowling12ISMCTS} and MMCTS~\cite{Auger11Multiple}.
We show results in synthetic game trees as well as several complex domains: Dudo, Phantom Tic-Tac-Toe, 
and (a bigger one). 

\vlnote{Current intro targets particularly the search community.}

\section{Background and Related Work}

%Overview of past algorithms and the current state-of-the-art (we have to ``weave'' the related work below into a nice overview).
%Define determinization, strategy fusion, non-locality, disambiguation factor. 
%References to help:
%\begin{itemize}
%\item Original/first II search~\cite{Frank98Finding}
%\item Work on Bridge~\cite{Ginsberg01}
%\item Information Set Search~(ISS)~\cite{Parker10iss,Parker06paranoia}
%%\vlnote{\cite{Parker10iss} is a little more detailed, but I guess it is from a less reputable forum.} 
%We have used ISS in MCTS setting in a visibility-based pursuit-evasion game~\cite{Lisy12peg}
%\item Work on Hearts / Spades~\cite{Sturtevant08An}
%\item PIMC~\cite{Long10Understanding} and other work on Skat (Jeff's thesis)
%\item Counter-examples in simple games~\cite{Shafiei09,Ponsen11Computing} 
%\item MMCTS (Phantom Tic-Tac-Toe)~\cite{Auger11Multiple}
%\item Work on Exp3 for Urban rivals~\cite{Teytaud11Upper,StPierre12Online}
%\item IS-MCTS~\cite{Cowling12ISMCTS} and other work by that group (on Dou di Zhu, MTG etc. \cite{Whitehouse11DDZ,Cowling12MTG})
%\item IIMC~\cite{Furtak13Recursive}
%\item Scotland Yard~\cite{Nijssen12SY}
%\item MCTS in Kriegspiel~\cite{Ciancarini10Kriegspiel}
%\item Kurt's past work on MCTS for Poker~\cite{vdbroek09MCTSPoker}?
%%\item MCTS in Kriegspiel~\cite{Ciancarini09Kriegspiel}
%%\vlnote{why not the AIJ 2010 paper?} 
%% ML: I did not know about it.
%\item Maybe quick mention of recent excitment in simultaneous move games (SMAB, double-oracle and serialized AB algorithm that doesn't have a name, SM-MCTS, and NIPS paper
%\item Mention that OOS has been applied in SM-MCTS setting.
%\end{itemize}

\subsection{Extensive Games and Equilibrium Computation}

Basic game theoretic definitions. Behavioral strategies. 
CFR~\cite{CFR} and MCCFR~\cite{Lanctot09Sampling}. Success in Poker.

\section{Online Outcome Sampling}

Complexities of online search vs. offline equilibrium computation. Notions of subgame perfection (sequential equilibrium). Information set targeted search. Epistemic depth.
Convergence theorems. Algorithm description.

\section{Empirical Evaluation}

Try it in a few complex domains, but some smaller ones as well to compare to offline-computed approximate equilibrium strategies and compute exploitability, and in random games. 
Hopefully it works well. I think to convince people doing work in this area, we'll need 
to compare to one or two of the state-of-the-art algorithms. 

\section{Conclusion}

\bibliographystyle{aaai}
\bibliography{iioos}

\end{document}
