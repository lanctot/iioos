%File: formatting-instruction.tex
\documentclass[letterpaper]{article}
\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{color}
\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}
\pdfinfo{
/Title (Searching Imperfect Information Games using Online Counterfactual Regret Minimization)
/Author (Authors)}
\setcounter{secnumdepth}{0}  
 \begin{document}
% The file aaai.sty is the style file for AAAI Press 
% proceedings, working notes, and technical reports.
%
\title{Monte Carlo Tree Search in Imperfect Information Games\\using Online Counterfactual Regret Minimization}
\author{Authors}
%\author{Author info\\
%Association for the Advancement of Artificial Intelligence\\
%2275 East Bayshore Road, Suite 160\\
%Palo Alto, California 94303\\

\newcounter{vlNoteCounter}
\newcommand{\vlnote}[1]{{\scriptsize \color{blue} \refstepcounter{vlNoteCounter}\textsf{[VL]$_{\arabic{vlNoteCounter}}$:{#1}}}}
%\renewcommand{\vlnote}[1]{}

\maketitle

\begin{abstract}
Online search in games has been a classic interest of artificial intelligence.
Advances made in search for perfect information games (such as Chess, Checkers, Go, and Backgammon) have led to AI capable of defeating the world's top human experts. 
The progress of search in imperfect information games (such as Poker, Bridge, and Skat) has comparatively lagged behind, due mainly to the complexities introduced by hiding information. 
In this paper, we present Online Outcome Sampling (OOS), the first imperfect information search algorithm with formal guarantees of convergence to an equilibrium strategy.   
In addition, we show that OOS avoids the common problems encountered by determinization.
We evaluate the practical performance and convergence rate of OOS and two recent imperfect information search algorithms. OOS performs better than its competitors in randomly generated game trees as well as several complex domains: 
Phantom Tic-Tac-Toe, Bluff, and Scotland Yard.  
\end{abstract}

\section{Introduction}

Main points: 
\begin{itemize}
\item motivate importance of convergence to NE. 
\item why online search vs. offline equilibrium computation
\item existing methods may not converge over time (it would be great to have a motivating example that convinces the reader that any determinization-based II search algorithm cannot converge in general - some kind of search game could be a good example)
\item introduce the first one that does, and show that it can compete with the others in practice
\end{itemize}

\section{Background and Related Work}

Overview of past algorithms and the current state-of-the-art (we have to ``weave'' the related work below into a nice overview).
Define determinization, strategy fusion, non-locality, disambiguation factor. 

References to help:
\begin{itemize}
\item Original/first II search~\cite{Frank98Finding}
\item Work on Bridge~\cite{Ginsberg01}
\item Information Set Search~(ISS)~\cite{Parker10iss,Parker06paranoia}
%\vlnote{\cite{Parker10iss} is a little more detailed, but I guess it is from a less reputable forum.} 
We have used ISS in MCTS setting in a visibility-based pursuit-evasion game~\cite{Lisy12peg}
\item Work on Hearts / Spades~\cite{Sturtevant08An}
\item PIMC~\cite{long2010understanding} and other work on Skat (Jeff's thesis)
\item Counter-examples in simple games~\cite{Shafiei09,Ponsen11Computing} 
\item MMCTS~\cite{Auger11Multiple}
\item Work on Exp3 for Urban rivals~\cite{Teytaud11Upper,StPierre12Online}
\item IS-MCTS~\cite{Cowling12ISMCTS} and other work by that group (on Dou di Zhu, MTG etc. \cite{Whitehouse11DDZ,Cowling12MTG})
\item IIMC~\cite{Furtak13Recursive}
\item Scotland Yard~\cite{Nijssen12SY}
\item MCTS in Kriegspiel~\cite{Ciancarini10Kriegspiel}
%\item MCTS in Kriegspiel~\cite{Ciancarini09Kriegspiel}
%\vlnote{why not the AIJ 2010 paper?} 
% ML: I did not know about it.
\item Maybe quick mention of recent excitment in simultaneous move games (SMAB, double-oracle and serialized AB algorithm that doesn't have a name, SM-MCTS, and NIPS paper
\item Mention that OOS has been applied in SM-MCTS setting.
\end{itemize}

\subsection{Extensive Games and Equilibrium Computation}

Basic game theoretic definitions. Behavioral strategies. 
CFR~\cite{CFR} and MCCFR~\cite{Lanctot09Sampling}. Success in Poker.

\section{Online Outcome Sampling}

Complexities of online search vs. offline equilibrium computation. Notions of subgame perfection (sequential equilibrium). Information set targeted search. Epistemic depth.
Convergence theorems. Algorithm description.

\section{Empirical Evaluation}

Try it in a few complex domains, but some smaller ones as well to compare to offline-computed approximate equilibrium strategies and compute exploitability, and in random games. 
Hopefully it works well. {\tt :)} I think to convince people doing work in this area, we'll need 
to compare to one or two of the state-of-the-art algorithms. 

\section{Conclusion}

OOS rocks the body that rocks the party! {\tt :-p}  


\bibliographystyle{aaai}
\bibliography{iioos}

\end{document}
