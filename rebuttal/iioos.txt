
We thank the reviewers for the valuable feedback; this will certainly help us improve the paper.  

To the best of our knowledge, there is no literature on approximating the exploitability of partial strategies computed by a search algorithm. Both full-stitching and aggregate methods are new. Full-stitching best represents the (observed/sampled) exploitability of a complete strategy (parameterized by the search time) that would be produced by a search algorithm if it was run from every possible match history; however, it is impractical in most cases. The aggregate method is more practical, but is an approximation.  

Regarding clarity of presentation, we have attempted to best summarize the work upon which OOS is based. A(h), A(I), and \sigma^t are defined on pages 2-3. u(\sigma) is an expectation over all possible terminal histories. We chose to describe the ideas formally to permit a precise description of the new sampling schemes, the algorithm itself, and Theorem 1. This left little space for examples and diagrams, and we refer the interested readers to previous work on MCCFR and imperfect information search. 

Clarifications regarding PST: a public action is an action in the 'public tree' defined in (Johanson et al, "Efficient Nash Equilibrium Approximation through Monte Carlo Counterfactual Regret Minimization", 2011). Informally, an action is said to be public if it is observable by all players (e.g. a bid in Liar's Dice is public, no action in II-Goofspiel is public). Formally, a sequence of legal actions from I to I', S(I,I'), is said to be a 'public action sequence' if every two histories h,h' \in I: hL \in I' and h'L \in I' and S(I,I') describes a one-to-one correspondence between histories in I and histories in I'. A public action, a \in A(I), is one such that every sequence containing a as the first action, S(I,I') = a S(I'',I') where I' is a successor of I is a public action sequence. A public subgame then, for example in LD, contains all the terminal histories consistent with the bidding sequence played over the match and each combination of private chance events for both players. 

OOS is not intended to be used as new (offline) solving technique. (MC)CFR cannot be practically applied in the online search setting without apriori knowledge (e.g. general game-playing); even offline use requires significant abstraction and precomputation for large games, e.g. Poker.
The 0.001-equilibrium players were produced using an efficient implementation of MCCFR and required several minutes to compute. 

We intentionally chose small games because it permits fundamental analysis+discussion. For instance, in LD(1,1) exploitabilities of strategies (which require full tree passes) are obtainable, so we could show that an increase in search time leads to a decrease in exploitability. This also allows inspecting the strategy produced by IS-MCTS, allowing us to relate it to ISMCTS behavior in Fig.1 and to similar paranoid behavior in previous work. Producing results in larger games is the desirable next step; this paper focuses on establishing observed practical consistency in domains for which this is possible. 

