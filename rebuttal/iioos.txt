
We thank the reviewers for the valuable feedback; this will certainly help us improve the paper.  

To the best of our knowledge, there is no literature that attempts to measure/approximate the exploitability of partial strategies computed by a search algorithm. The full stitching and aggregate methods are new. The full-stitching method best represents the (observed/sampled) exploitability of a complete strategy (parameterized by the search time) that would be produced by a search algorithm if it was run from every possible match; however, it is impractical in most cases. The aggregate method is more practical, however is an approximation.  

Regarding clarity of presentation, we have attempted to best summarize the work upon which OOS is based. We chose to describe the ideas formally to permit a precise description of the new sampling schemes, the algorithm itself, and Theorem 1. However, this did not leave much space for examples and diagrams, and we refer the interested readers to previous work on MCCFR and imperfect information search. 

Clarifications regarding PST: a public action is an action in the 'public tree' defined in (Johanson et al, "Efficient Nash Equilibrium Approximation through Monte Carlo Counterfactual Regret Minimization", 2011). Informally, an action is said to be public if it is observable by all players (e.g. a bid in Liar's Dice is public, no action in II-Goofspiel is public). Formally, a sequence of legal actions from I to I', S(I,I'), is said to be a 'public action sequence' if every two histories h,h' \in I: hL \in I' and h'L \in I' and S(I,I') describes a one-to-one correspondence between histories in I and histories in I'. A public action, a \in A(I), is one such that every sequence containing a as the first action, S(I,I') = a S(I'',I') where I' is a successor of I is a public action sequence. A public subgame then, for example in LD, contains all the terminal histories consistent with the bidding sequence played over the match and for each private outcome of chance for both players. 

OOS is not intended to be used as new (offline) solving technique. (MC)CFR cannot be practically applied in the online search setting without apriori knowledge (e.g. general game-playing). Even their offline use requires significant abstraction and precomputation for large games, e.g. Poker. Nevertheless, the 0.001-equilibrium players were produced using an efficient implementation of MCCFR and required several minutes to compute. OOS almost matches its performance in a few seconds of search time. 

We intentionally chose small games because it permits fundamental analysis+discussion. For instance, in LD(1,1) exploitabilities of strategies (which require full tree passes) are obtainable, so we could show that an increase in search leads to a decrease in exploitability for short time settings. This also allows inspecting the strategy produced by IS-MCTS, allowing us to relate it to example in Fig.1 and to similar behavior in previous work. Producing results in larger games is the desirable next step; this paper focuses on establishing observed practical consistency in domains for which this is possible. 

